{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Self-Organising Maps - COLORES\n",
    "## Preparación de entorno\n",
    "#### Importar librerías de código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as patches\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset que se va a utilizar para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Código para obtener el Dataset que se va a usar en el entrenamiento\n",
    "datosOriginal = pd.read_csv(\"pokemon_train.csv\", encoding = 'latin_1', sep = ',')\n",
    "datosDF = datosOriginal\n",
    "nombres_pokemon = datosDF.pop(\"name\")\n",
    "tipos_pokemon_type1 = datosDF.pop(\"type1\")\n",
    "tipos_pokemon_type2 = datosDF.pop(\"type2\")\n",
    "id_pokemon = datosDF.pop(\"id\")\n",
    "\n",
    "datosClasificarDF = pd.read_csv(\"pokemon_classify.csv\", encoding = 'latin_1', sep = ',')\n",
    "datosClasificarDF = datosClasificarDF.drop([\"name\",\"type1\",\"type2\",\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Setup\n",
    "#### Variables definidas por el alumno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores de entradas \n",
    "n_entradas_kohonen = len(datosDF.columns) # 22 entradas \n",
    "tam_dataset = len(datosDF) # 247 valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inicializa tamaño del mapa de Kohonen, número de iteraciones y learning rate\n",
    "# Inicializa normalizar_datos dependiendo de si tienes que normalizar los datos o no\n",
    "lado_mapa = 30 # Cambiar\n",
    "periodo = 500 # Cambiar\n",
    "learning_rate = 0.15 # Cambiar\n",
    "normalizar_datos = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A partir de este punto solo hay cálculos. No se introducen más valores \"a mano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Establece el numero de entradas del mapa y el número de datos que se van a usar para entrenar. \n",
    "# Utiliza una función que obtenga automáticamente los valores a partir del Dataset.\n",
    "num_entradas = n_entradas_kohonen\n",
    "num_datos = tam_dataset\n",
    "\n",
    "# Calcula el vecindario inicial. Debe ser la mitad del lado del mapa de Kohonen\n",
    "vecindario_inicial = int(lado_mapa/2)\n",
    "\n",
    "# Normaliza los datos si fuese necesario dividiendo cada dato por el máximo en la matriz\n",
    "if normalizar_datos:\n",
    "    datosAR = datosDF.to_numpy()\n",
    "    datosAR = (datosAR - datosAR.min()) / ( datosAR.max() - datosAR.min())\n",
    "    \n",
    "# Crea una matriz de pesos con valores random entre 0 y 1. Usa la función random.random de la librería NumPy\n",
    "matriz_pesos = np.random.random((lado_mapa,lado_mapa,num_entradas))\n",
    "matriz_pesos_original = matriz_pesos # La guardamos para poder comparar en un futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones para entrenar/clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion calcular BMU\n",
    "def calcular_bmu(patron_entrada, m_pesos):\n",
    "   # Obtenemos dimensiones de la matriz de pesos para los bucles\n",
    "   rows = len(m_pesos)\n",
    "   columns = len(m_pesos[0])\n",
    "   # Decimos que la ganadora al principio sea la primera neurona\n",
    "   ganadora = np.linalg.norm(np.array(m_pesos[0][0]) - np.array(patron_entrada))\n",
    "   Bmu = m_pesos[0][0]\n",
    "   BmuIndex = np.stack((0,0))\n",
    "   # Bucle que recorre toda las neuronas\n",
    "   for x in range(rows):\n",
    "      for y in range(columns):\n",
    "         # Obten la distancia euclidea entre la neurona y el patron\n",
    "         dist = np.linalg.norm(np.array(m_pesos[x][y]) - np.array(patron_entrada))\n",
    "         # Si la nueva distancia es menor que la ganadora asigna esta neurona como la nueva ganadora\n",
    "         if dist < ganadora:\n",
    "            ganadora = dist\n",
    "            Bmu = m_pesos[x][y]\n",
    "            BmuIndex = np.stack((x,y))\n",
    "   return Bmu , BmuIndex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para calcular el descenso del coeficiente de aprendizaje (eta)\n",
    "\"\"\"\n",
    "   Calcula el Learning Rate (eta) que corresponde a la i-ésima presentación.\n",
    "   Entradas: (learning_rate_inicial, iteracion, período)\n",
    "   Salidas:  learning_rate para la iteración i\n",
    "\n",
    "\"\"\"\n",
    "def variacion_learning_rate(lr_inicial, i, n_iteraciones):\n",
    "   learning_rate = lr_inicial * (1 - i/n_iteraciones)\n",
    "   return learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para calcular el descenso del vecindario (v)\n",
    "\"\"\"\n",
    "   Calcula el vecindario  (v) que corresponde a la i-ésima presentación.\n",
    "   Entradas: (vecindario_inicial, iteracion, período)\n",
    "   Salidas:  lvecindario para la iteración i\n",
    "\n",
    "\"\"\"\n",
    "def variacion_vecindario(vecindario_inicial, i, n_iteraciones):\n",
    "   vecindario = 1 + vecindario_inicial * (1 - i/n_iteraciones)\n",
    "   return vecindario\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para calcular el descenso del coeficiente de aprendizaje (eta) en función de la distancia a la BMU\n",
    "\"\"\"\n",
    "   Calcula la amortiguación de eta en función de la distancia en el mapa entre una neurona y la BMU.\n",
    "   Entradas: (distancia_BMU, vecindario_actual)\n",
    "   Salidas:  amortiguación para la iteración\n",
    "\n",
    "\"\"\"\n",
    "def decay(distancia_BMU, vecindario_actual):\n",
    "    return np.exp(-distancia_BMU**2 / (2*vecindario_actual**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion Ajuste de matriz de pesos\n",
    "def ajustarPesos(IndexN , pokemon , learning_rate , matriz_pesos , vecindario):\n",
    "    # Formula para obtener los pesos nuevos de la BMUW\n",
    "    matriz_pesos[IndexN[0]][IndexN[1]] += (learning_rate * (pokemon - matriz_pesos[IndexN[0]][IndexN[1]]))\n",
    "    # Obtenemos las dimensiones para el bucle\n",
    "    rows = len(matriz_pesos)\n",
    "    cols = len(matriz_pesos[0])\n",
    "    # Bucle que recorre todas la neuronas incluida la BMU\n",
    "    for x in range(rows):\n",
    "        for y in range(cols):\n",
    "            vectorNeurona = [x,y] #Guardamos el indice como un vector\n",
    "            vectorBMU = [IndexN[0],IndexN[1]] #Guardamos el indice como un vecto\n",
    "            #Calculamos la discacia euclidea entre ambos vectores para determinar como de lejos estan los indices\n",
    "            dist_euc = np.linalg.norm(np.array(vectorBMU) - np.array(vectorNeurona)) \n",
    "            # Si la distancia es menor o igual que el vecindario y no es 0 (caso de la BMU) entonces sabemos que es vecina de BMU\n",
    "            if(dist_euc <= vecindario and dist_euc != 0):\n",
    "              # Dime segun la distancia entre la neuroma vecina y la bmu cuanto es el decay del learning rate\n",
    "              dist_decay = decay(dist_euc,vecindario)\n",
    "              # Aplico formula de ajuste de pesos a la neurona vecina segun los datos obtenidos\n",
    "              matriz_pesos[x][y] += (learning_rate * dist_decay * (pokemon -  matriz_pesos[x][y]))  \n",
    "    return matriz_pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINTAR HISTOGRAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion Nº:  500\n"
     ]
    }
   ],
   "source": [
    "# Entrena la red con el dataset de entrenamiento\n",
    "# Guardamos las variables iniciales para no modificarlas en las iteraciones de entrenamiento\n",
    "vecindario = vecindario_inicial\n",
    "learning_rate_ajustado = learning_rate\n",
    "for x in range(periodo):\n",
    "    # Imprime la iteracion actual cada 100 iteraciones\n",
    "    if(x % 100 == 0 and x != 0):\n",
    "        print('Iteracion Nº: ',x,end=\"\\r\")\n",
    "    #Obtenemos un indice aleatorio de nuestro set de pokemon\n",
    "    numAleatorio = np.random.randint(0, tam_dataset)\n",
    "    pokemon = datosAR[numAleatorio] \n",
    "    #Pasamos el pokemon aleatorio a calcular bmu para que nos devuelva la neurona mas proxima al patron\n",
    "    Bmu , BmuIndex = calcular_bmu(pokemon,matriz_pesos)\n",
    "    #Ajustamos la matrix de pesos segun los datos obtenidos\n",
    "    matriz_pesos = ajustarPesos(BmuIndex , pokemon , learning_rate_ajustado , matriz_pesos , vecindario)\n",
    "    #Una vez ajustada la matriz de pesos modificamos el learning rate para la siguiente iteracion\n",
    "    learning_rate_ajustado = variacion_learning_rate(learning_rate, x , periodo)\n",
    "    #Una vez ajustada la matriz de pesos modificamos el vecindario para la siguiente iteracion\n",
    "    vecindario = variacion_vecindario(vecindario_inicial , x , periodo)\n",
    "\n",
    "print('Iteracion Nº: ',x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Clases:  54\n"
     ]
    }
   ],
   "source": [
    "# Clasifica los patrones de entrenamiento con la matriz de pesos recién entrenada\n",
    "\n",
    "def Clasificacion(pokemon , matriz_pesos):\n",
    "\n",
    "    Mapa_Clasificacion = np.zeros((lado_mapa,lado_mapa,num_entradas))\n",
    "    Mapa_Activacion = np.zeros((lado_mapa,lado_mapa),dtype=int)\n",
    "    Mapa_Distancias = np.zeros((lado_mapa,lado_mapa))\n",
    "\n",
    "    clase = 0\n",
    "\n",
    "    for poke in pokemon:\n",
    "        bmu , bmuIndex = calcular_bmu(poke,matriz_pesos)\n",
    "        Mapa_Activacion[bmuIndex[0],bmuIndex[1]] += 1 # Cada vez que se activa una neurona (x,y de la ganadora ++)\n",
    "        #print(\"Neurona gandora: \", bmuIndex)\n",
    "        Mapa_Clasificacion[bmuIndex[0],bmuIndex[1]] = poke # Se guarda el último color que ha activado la neurona\n",
    "        # La media de las distancias euclidieas de esa neurona\n",
    "        Mapa_Distancias[bmuIndex[0],bmuIndex[1]] = (Mapa_Distancias[bmuIndex[0],bmuIndex[1]] + np.linalg.norm(np.array(bmu) - np.array(poke))) / 2 \n",
    "        \n",
    "    for x in range(len(Mapa_Activacion)):\n",
    "        for y in range(len(Mapa_Activacion[0])):\n",
    "            if Mapa_Activacion[x][y] > 0:\n",
    "                clase += 1\n",
    "\n",
    "    print('Numero de Clases: ', clase)\n",
    "    return Mapa_Activacion, Mapa_Clasificacion, Mapa_Distancias\n",
    "\n",
    "\n",
    "Mapa_Activacion, Mapa_Clasificacion, Mapa_Distancias = Clasificacion(datosAR, matriz_pesos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (18,) (247,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4858/9399699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdatosClasificar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatosClasificar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mMapa_Activacion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapa_Clasificacion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapa_Distancias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClasificacion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatosClasificar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatriz_pesos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Funcion para calcular el error de cuantificacion dado un mapa de Distancias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCalcular_err_cuantificacion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMapa_Distancias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4858/1528683276.py\u001b[0m in \u001b[0;36mClasificacion\u001b[0;34m(pokemon, matriz_pesos)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpoke\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpokemon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mbmu\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbmuIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcular_bmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatriz_pesos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mMapa_Activacion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbmuIndex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbmuIndex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# Cada vez que se activa una neurona (x,y de la ganadora ++)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(\"Neurona gandora: \", bmuIndex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4858/120224527.py\u001b[0m in \u001b[0;36mcalcular_bmu\u001b[0;34m(patron_entrada, m_pesos)\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_pesos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0;31m# Decimos que la ganadora al principio sea la primera neurona\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m    \u001b[0mganadora\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_pesos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatron_entrada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m    \u001b[0mBmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_pesos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mBmuIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (18,) (247,) "
     ]
    }
   ],
   "source": [
    "# Clasifica nuevos patrones\n",
    "\n",
    "#datosClasificar = np.random.rand(18,100)\n",
    "datosClasificar = datosAR\n",
    "#datosClasificar = np.transpose(datosClasificar)\n",
    "\n",
    "Mapa_Activacion, Mapa_Clasificacion, Mapa_Distancias = Clasificacion(datosClasificar, matriz_pesos)\n",
    "# Funcion para calcular el error de cuantificacion dado un mapa de Distancias\n",
    "def Calcular_err_cuantificacion(Mapa_Distancias):\n",
    "    ListaDistancia = []\n",
    "    for x in range(len(Mapa_Distancias)):\n",
    "        for y in range(len(Mapa_Distancias[0])):\n",
    "            if Mapa_Distancias[x][y] != 0:\n",
    "             ListaDistancia.append(Mapa_Distancias[x][y])\n",
    "    Media = sum(ListaDistancia) / len(ListaDistancia)\n",
    "    return Media\n",
    "\n",
    "# Funcion que devuelve si la segunda bmu es adyacente o no dado un patron\n",
    "def calcular_err_topologico(patron_entrada, m_pesos):\n",
    "    rows = len(m_pesos)\n",
    "    columns = len(m_pesos[0])\n",
    "    # Asignamos que la ganadora 1 sea la primera neurona y la ganadora 2 la segunda por tener un valor con cual empezar\n",
    "    ganadora = np.linalg.norm(np.array(m_pesos[0][0]) - np.array(patron_entrada))\n",
    "    ganadora2 = np.linalg.norm(np.array(m_pesos[0][1]) - np.array(patron_entrada))\n",
    "    BmuIndex = np.stack((0,0))\n",
    "    Bmu2Index = np.stack((0,1))\n",
    "    # Mismo algoritmo que CalcularBMU pero en este se guarda la segunda BMU\n",
    "    for x in range(rows):\n",
    "        for y in range(columns):\n",
    "            dist = np.linalg.norm(np.array(m_pesos[x][y]) - np.array(patron_entrada))\n",
    "            if dist < ganadora:\n",
    "                ganadora = dist\n",
    "                BmuIndex = np.stack((x,y))\n",
    "            else:\n",
    "                if dist < ganadora2:\n",
    "                    ganadora2 = dist\n",
    "                    Bmu2Index = np.stack((x,y))\n",
    "    # Devuelve 0 si es adyacente y 1 en el caso contrario\n",
    "    return (0 if np.linalg.norm(np.array(BmuIndex)-np.array(Bmu2Index)) < 2 else 1)\n",
    "\n",
    "# Aqui calculamos e imprimimos los errores\n",
    "print('Error De Cuantificacion: ', Calcular_err_cuantificacion(Mapa_Distancias))\n",
    "listaX = []\n",
    "\n",
    "# Dado un set de colores guarda en una lista los valores devueltos\n",
    "for pokemon in datosClasificar:\n",
    "    listaX.append(calcular_err_topologico(pokemon,matriz_pesos))\n",
    "# Calculamos la Media\n",
    "media = sum(listaX) / len(listaX)\n",
    "print('Error Topologico: ', media)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
